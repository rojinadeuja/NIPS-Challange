{
 "cells": [
  {
   "attachments": {
    "image.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BENCHMARKING CLASSIFIERS\n",
    "### PROCESS\n",
    "\n",
    "Feed Unprocessed Data into Classifiers and Measure Accuracy\n",
    "\n",
    "So firstly, we will feed the unprocessed dataset (with Standardization carried out) into 4 classfiers and compare their performances:\n",
    "1. Logistic Regression\n",
    "- KNeighbors Classifier\n",
    "- Decision Tree Classifier\n",
    "- Support Vector Classifier\n",
    "\n",
    "**From the above, we will chose a classfier as benchmark for our model. ie. We will use the benchmark model for all our future predictions on the dataset before and after the feature selection has been applied on the dataset so that we can correctly compare the effectiveness of our feature selection methodogies.**\n",
    "\n",
    "### RESULTS\n",
    "\n",
    "- **For both the training and testing dataset, the highest accuracy was achieved using the Decision Tree Classifier.**\n",
    "\n",
    "- In both cases, the Logistic Regression performed the worst on the test set.\n",
    "\n",
    "![image.png](attachment:image.png)\n",
    "#### Logistic Regression\n",
    "The logistic regression is a linear classifier as such it draws a linear decision boundary to separate the datasets. So, for our non-linear dataset we expect it to perform poorly and the obeserved accuracy scores confirm this. Logistic Regression can classify non-linear data only when data is augmented by projecting the features on a high-dimensioal space.\n",
    "\n",
    "#### KNeighbors Classifier\n",
    "The K Nearest Neighbors classifier from sklearn is a non-linear classifier. It can classify non-linear dataset by creating non-inear decision boundary. In the K-NN model there is no learning, thus we only tune the hyperparameters to create the optimal model. With no hyperparameter tuning, the model can't be expected to perform well. Moreover, our dataset has 500 dimension and KNN suffers from the curse of dimensionality. The curse of dimensionality affects the K-NN model in four ways:\n",
    "\n",
    "- In high-dimension all neighbors are far away (outliers)!\n",
    "- Distance calculation is expensive in high-dimension.\n",
    "- Number of required training data increases exponentially.\n",
    "- Large number of irrelevant features in high-dimensional data.\n",
    "\n",
    "#### Decision Tree\n",
    "Decision Tree Classifier from sklearn predicts the value of a target variable by using data observations to extract simple rules about the data. Decision trees can be fairly robust to noises as it can entirely ignore irrelevant features and only make decisions based on features significant in the classification. In all subsets, the accuracy scores were higher than other models.\n",
    "\n",
    "#### Support Vector Classifier\n",
    "In the SVC function from sklearn we use the kernel trick to project the data into a higher dimension. Since the data is non-linear, we use the Radial Basis Function (RBF) kernel. It suffers from a similar issue as the KNN Classifier--all features are maintained in the subset of instances used as support vectors, so the features that are noisy decrease the accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd, numpy as np\n",
    "import matplotlib.pyplot as plt, seaborn as sns\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC \n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from sklearn.metrics import classification_report, confusion_matrix, precision_score, recall_score, f1_score, roc_curve, precision_recall_curve, classification_report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the Data from Pickled DataFrames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>V10</th>\n",
       "      <th>...</th>\n",
       "      <th>V492</th>\n",
       "      <th>V493</th>\n",
       "      <th>V494</th>\n",
       "      <th>V495</th>\n",
       "      <th>V496</th>\n",
       "      <th>V497</th>\n",
       "      <th>V498</th>\n",
       "      <th>V499</th>\n",
       "      <th>V500</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>485</td>\n",
       "      <td>477</td>\n",
       "      <td>537</td>\n",
       "      <td>479</td>\n",
       "      <td>452</td>\n",
       "      <td>471</td>\n",
       "      <td>491</td>\n",
       "      <td>476</td>\n",
       "      <td>475</td>\n",
       "      <td>473</td>\n",
       "      <td>...</td>\n",
       "      <td>481</td>\n",
       "      <td>477</td>\n",
       "      <td>485</td>\n",
       "      <td>511</td>\n",
       "      <td>485</td>\n",
       "      <td>481</td>\n",
       "      <td>479</td>\n",
       "      <td>475</td>\n",
       "      <td>496</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>483</td>\n",
       "      <td>458</td>\n",
       "      <td>460</td>\n",
       "      <td>487</td>\n",
       "      <td>587</td>\n",
       "      <td>475</td>\n",
       "      <td>526</td>\n",
       "      <td>479</td>\n",
       "      <td>485</td>\n",
       "      <td>469</td>\n",
       "      <td>...</td>\n",
       "      <td>478</td>\n",
       "      <td>487</td>\n",
       "      <td>338</td>\n",
       "      <td>513</td>\n",
       "      <td>486</td>\n",
       "      <td>483</td>\n",
       "      <td>492</td>\n",
       "      <td>510</td>\n",
       "      <td>517</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>487</td>\n",
       "      <td>542</td>\n",
       "      <td>499</td>\n",
       "      <td>468</td>\n",
       "      <td>448</td>\n",
       "      <td>471</td>\n",
       "      <td>442</td>\n",
       "      <td>478</td>\n",
       "      <td>480</td>\n",
       "      <td>477</td>\n",
       "      <td>...</td>\n",
       "      <td>481</td>\n",
       "      <td>492</td>\n",
       "      <td>650</td>\n",
       "      <td>506</td>\n",
       "      <td>501</td>\n",
       "      <td>480</td>\n",
       "      <td>489</td>\n",
       "      <td>499</td>\n",
       "      <td>498</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>480</td>\n",
       "      <td>491</td>\n",
       "      <td>510</td>\n",
       "      <td>485</td>\n",
       "      <td>495</td>\n",
       "      <td>472</td>\n",
       "      <td>417</td>\n",
       "      <td>474</td>\n",
       "      <td>502</td>\n",
       "      <td>476</td>\n",
       "      <td>...</td>\n",
       "      <td>480</td>\n",
       "      <td>474</td>\n",
       "      <td>572</td>\n",
       "      <td>454</td>\n",
       "      <td>469</td>\n",
       "      <td>475</td>\n",
       "      <td>482</td>\n",
       "      <td>494</td>\n",
       "      <td>461</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>484</td>\n",
       "      <td>502</td>\n",
       "      <td>528</td>\n",
       "      <td>489</td>\n",
       "      <td>466</td>\n",
       "      <td>481</td>\n",
       "      <td>402</td>\n",
       "      <td>478</td>\n",
       "      <td>487</td>\n",
       "      <td>468</td>\n",
       "      <td>...</td>\n",
       "      <td>479</td>\n",
       "      <td>452</td>\n",
       "      <td>435</td>\n",
       "      <td>486</td>\n",
       "      <td>508</td>\n",
       "      <td>481</td>\n",
       "      <td>504</td>\n",
       "      <td>495</td>\n",
       "      <td>511</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 501 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    V1   V2   V3   V4   V5   V6   V7   V8   V9  V10  ...  V492  V493  V494  \\\n",
       "0  485  477  537  479  452  471  491  476  475  473  ...   481   477   485   \n",
       "1  483  458  460  487  587  475  526  479  485  469  ...   478   487   338   \n",
       "2  487  542  499  468  448  471  442  478  480  477  ...   481   492   650   \n",
       "3  480  491  510  485  495  472  417  474  502  476  ...   480   474   572   \n",
       "4  484  502  528  489  466  481  402  478  487  468  ...   479   452   435   \n",
       "\n",
       "   V495  V496  V497  V498  V499  V500  Class  \n",
       "0   511   485   481   479   475   496      2  \n",
       "1   513   486   483   492   510   517      2  \n",
       "2   506   501   480   489   499   498      2  \n",
       "3   454   469   475   482   494   461      1  \n",
       "4   486   508   481   504   495   511      1  \n",
       "\n",
       "[5 rows x 501 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''Load and quick check the data'''\n",
    "import pandas as pd\n",
    "df= pd.read_csv(\"medilon.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Madelon:** It's not necessary to load in the test set since that's the hold out data to test the classification model's accuracy. Train/test/split on the training data. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run the Data through the Classifiers and obtain Train & Test scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Madelon Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>V10</th>\n",
       "      <th>...</th>\n",
       "      <th>V492</th>\n",
       "      <th>V493</th>\n",
       "      <th>V494</th>\n",
       "      <th>V495</th>\n",
       "      <th>V496</th>\n",
       "      <th>V497</th>\n",
       "      <th>V498</th>\n",
       "      <th>V499</th>\n",
       "      <th>V500</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>485</td>\n",
       "      <td>477</td>\n",
       "      <td>537</td>\n",
       "      <td>479</td>\n",
       "      <td>452</td>\n",
       "      <td>471</td>\n",
       "      <td>491</td>\n",
       "      <td>476</td>\n",
       "      <td>475</td>\n",
       "      <td>473</td>\n",
       "      <td>...</td>\n",
       "      <td>481</td>\n",
       "      <td>477</td>\n",
       "      <td>485</td>\n",
       "      <td>511</td>\n",
       "      <td>485</td>\n",
       "      <td>481</td>\n",
       "      <td>479</td>\n",
       "      <td>475</td>\n",
       "      <td>496</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>483</td>\n",
       "      <td>458</td>\n",
       "      <td>460</td>\n",
       "      <td>487</td>\n",
       "      <td>587</td>\n",
       "      <td>475</td>\n",
       "      <td>526</td>\n",
       "      <td>479</td>\n",
       "      <td>485</td>\n",
       "      <td>469</td>\n",
       "      <td>...</td>\n",
       "      <td>478</td>\n",
       "      <td>487</td>\n",
       "      <td>338</td>\n",
       "      <td>513</td>\n",
       "      <td>486</td>\n",
       "      <td>483</td>\n",
       "      <td>492</td>\n",
       "      <td>510</td>\n",
       "      <td>517</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>487</td>\n",
       "      <td>542</td>\n",
       "      <td>499</td>\n",
       "      <td>468</td>\n",
       "      <td>448</td>\n",
       "      <td>471</td>\n",
       "      <td>442</td>\n",
       "      <td>478</td>\n",
       "      <td>480</td>\n",
       "      <td>477</td>\n",
       "      <td>...</td>\n",
       "      <td>481</td>\n",
       "      <td>492</td>\n",
       "      <td>650</td>\n",
       "      <td>506</td>\n",
       "      <td>501</td>\n",
       "      <td>480</td>\n",
       "      <td>489</td>\n",
       "      <td>499</td>\n",
       "      <td>498</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>480</td>\n",
       "      <td>491</td>\n",
       "      <td>510</td>\n",
       "      <td>485</td>\n",
       "      <td>495</td>\n",
       "      <td>472</td>\n",
       "      <td>417</td>\n",
       "      <td>474</td>\n",
       "      <td>502</td>\n",
       "      <td>476</td>\n",
       "      <td>...</td>\n",
       "      <td>480</td>\n",
       "      <td>474</td>\n",
       "      <td>572</td>\n",
       "      <td>454</td>\n",
       "      <td>469</td>\n",
       "      <td>475</td>\n",
       "      <td>482</td>\n",
       "      <td>494</td>\n",
       "      <td>461</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>484</td>\n",
       "      <td>502</td>\n",
       "      <td>528</td>\n",
       "      <td>489</td>\n",
       "      <td>466</td>\n",
       "      <td>481</td>\n",
       "      <td>402</td>\n",
       "      <td>478</td>\n",
       "      <td>487</td>\n",
       "      <td>468</td>\n",
       "      <td>...</td>\n",
       "      <td>479</td>\n",
       "      <td>452</td>\n",
       "      <td>435</td>\n",
       "      <td>486</td>\n",
       "      <td>508</td>\n",
       "      <td>481</td>\n",
       "      <td>504</td>\n",
       "      <td>495</td>\n",
       "      <td>511</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 501 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    V1   V2   V3   V4   V5   V6   V7   V8   V9  V10  ...  V492  V493  V494  \\\n",
       "0  485  477  537  479  452  471  491  476  475  473  ...   481   477   485   \n",
       "1  483  458  460  487  587  475  526  479  485  469  ...   478   487   338   \n",
       "2  487  542  499  468  448  471  442  478  480  477  ...   481   492   650   \n",
       "3  480  491  510  485  495  472  417  474  502  476  ...   480   474   572   \n",
       "4  484  502  528  489  466  481  402  478  487  468  ...   479   452   435   \n",
       "\n",
       "   V495  V496  V497  V498  V499  V500  Class  \n",
       "0   511   485   481   479   475   496      2  \n",
       "1   513   486   483   492   510   517      2  \n",
       "2   506   501   480   489   499   498      2  \n",
       "3   454   469   475   482   494   461      1  \n",
       "4   486   508   481   504   495   511      1  \n",
       "\n",
       "[5 rows x 501 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(['Class'], axis = 1)\n",
    "y = df['Class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler().fit(X)\n",
    "X = scaler.transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Raw Benchmarking with only Standardization for Pre-Preprocessing\n",
    "We use the out of box default parameters provided by `sklearn` for the selected classification models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier_list = ['Logistic Regression', 'K Nearest Neighbors', 'Decision Tree', 'SVC']\n",
    "\n",
    "classifiers = [\n",
    "    LogisticRegression(n_jobs=-1, random_state=42),\n",
    "    KNeighborsClassifier(),\n",
    "    DecisionTreeClassifier(random_state=42),\n",
    "    SVC(kernel= 'rbf', random_state=42)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\rojin\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "c:\\users\\rojin\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:1544: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 8.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n",
      "c:\\users\\rojin\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "test_scores = {}\n",
    "train_scores = {}\n",
    "y_pred = {}\n",
    "\n",
    "for name, clfr in zip(classifier_list, classifiers):\n",
    "    clfr.fit(X_train, y_train)\n",
    "    \n",
    "    train_score = clfr.score(X_train, y_train)\n",
    "    test_score = clfr.score(X_test, y_test)\n",
    "    pred = clfr.predict(X_test)\n",
    "    \n",
    "    train_scores[name] = train_score\n",
    "    test_scores[name] = test_score\n",
    "    y_pred[name] = pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracies:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'Logistic Regression': 0.7471153846153846,\n",
       " 'K Nearest Neighbors': 0.7163461538461539,\n",
       " 'Decision Tree': 1.0,\n",
       " 'SVC': 0.9725961538461538}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('Train Accuracies:')\n",
    "train_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracies:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'Logistic Regression': 0.5269230769230769,\n",
       " 'K Nearest Neighbors': 0.575,\n",
       " 'Decision Tree': 0.7403846153846154,\n",
       " 'SVC': 0.575}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('Test Accuracies:')\n",
    "test_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performance measures for test set:\n",
      "------ Decision Tree\n",
      "Accuracy: 0.7403846153846154\n",
      "F1 Score: 0.7457627118644069\n",
      "Precision Score: 0.7226277372262774\n",
      "Recall Score: 0.7704280155642024\n",
      "Confusion Matrix:\n",
      " [[198  59]\n",
      " [ 76 187]]\n",
      "\n",
      "------ K Nearest Neighbors\n",
      "Accuracy: 0.575\n",
      "F1 Score: 0.5386221294363256\n",
      "Precision Score: 0.581081081081081\n",
      "Recall Score: 0.5019455252918288\n",
      "Confusion Matrix:\n",
      " [[129 128]\n",
      " [ 93 170]]\n",
      "\n",
      "------ Logistic Regression\n",
      "Accuracy: 0.5269230769230769\n",
      "F1 Score: 0.5427509293680297\n",
      "Precision Score: 0.5195729537366548\n",
      "Recall Score: 0.5680933852140078\n",
      "Confusion Matrix:\n",
      " [[146 111]\n",
      " [135 128]]\n",
      "\n",
      "------ SVC\n",
      "Accuracy: 0.575\n",
      "F1 Score: 0.5725338491295937\n",
      "Precision Score: 0.5692307692307692\n",
      "Recall Score: 0.5758754863813229\n",
      "Confusion Matrix:\n",
      " [[148 109]\n",
      " [112 151]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('Performance measures for test set:')\n",
    "for classifier in sorted(classifier_list):\n",
    "    print('------',classifier)\n",
    "    print('Accuracy:', test_scores[classifier])\n",
    "    print('F1 Score:',f1_score(y_test, y_pred[classifier]))\n",
    "    print('Precision Score:',precision_score(y_test, y_pred[classifier]))\n",
    "    print('Recall Score:', recall_score(y_test, y_pred[classifier]))\n",
    "    print('Confusion Matrix:\\n', confusion_matrix(y_test, y_pred[classifier]))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Reports:\n",
      "---------- Logistic Regression\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.52      0.57      0.54       257\n",
      "           2       0.54      0.49      0.51       263\n",
      "\n",
      "    accuracy                           0.53       520\n",
      "   macro avg       0.53      0.53      0.53       520\n",
      "weighted avg       0.53      0.53      0.53       520\n",
      "\n",
      "---------- K Nearest Neighbors\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.58      0.50      0.54       257\n",
      "           2       0.57      0.65      0.61       263\n",
      "\n",
      "    accuracy                           0.57       520\n",
      "   macro avg       0.58      0.57      0.57       520\n",
      "weighted avg       0.58      0.57      0.57       520\n",
      "\n",
      "---------- Decision Tree\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.72      0.77      0.75       257\n",
      "           2       0.76      0.71      0.73       263\n",
      "\n",
      "    accuracy                           0.74       520\n",
      "   macro avg       0.74      0.74      0.74       520\n",
      "weighted avg       0.74      0.74      0.74       520\n",
      "\n",
      "---------- SVC\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.57      0.58      0.57       257\n",
      "           2       0.58      0.57      0.58       263\n",
      "\n",
      "    accuracy                           0.57       520\n",
      "   macro avg       0.57      0.58      0.57       520\n",
      "weighted avg       0.58      0.57      0.58       520\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('Classification Reports:')\n",
    "for classifier in classifier_list:\n",
    "    print('----------',classifier)\n",
    "    print(classification_report(y_test, y_pred[classifier]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusion:\n",
    "The DecisionTreeClassifier gives us the highest accuracy for both the train and test set, so we will use it as the bench mark model"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
